from whoosh.index import create_in
from whoosh.fields import *
import os, os.path
import pandas as pd
from elasticsearch import Elasticsearch

# Codice per la creazione dell'indice / degli indici.


#Creazione del primo II di Whoosh, utilizzo dello standard Analyzer

    
'''
schema = Schema(
    title=TEXT(stored=True),        #SOLO "TEXT" subir√† pre-processing
    year=ID(stored=True),
    genre=KEYWORD(stored=True, commas=True), 
    country=KEYWORD(stored=True),  
    plot=TEXT(stored=False),                                                                                   
)
'''
'''
schema = Schema(
    title=TEXT(stored=True),        
    year=TEXT(stored=True),
    genre=TEXT(stored=True), 
    country=TEXT(stored=True),  
    plot=TEXT(stored=False),                                                                                   
)

directory = os.path.join("Whoosh", "II_stdAnalyzer")            #Soluzione portabile
if not os.path.exists(directory):
    os.makedirs(directory)     

ix = create_in(directory, schema)

writer = ix.writer()          


# Carica il dataset CSV
file = os.path.join("dataset-constr", "films.csv") 
df = pd.read_csv(file)



# Aggiungi i documenti all'indice specificando i vari campi
for indice, films in df.iterrows():
    writer.add_document(    title=films["Title"], 
                            year= str(films["Year"]),
                            genre=films["Genre"],
                            country=films["Country"],
                            plot=films["Plot"]
                               )
 
writer.commit()


print("Indicizzazione primo II completata!")

'''


#Creazione del'II del Gold Standard


# Connessione al servizio di  Elasticsearch 
# NECESSITA CHE IL SERVIZIO SIA ATTIVO (vari modi per scaricarlo, io lo ho scaricato da internet (elastic.co/download))
# estratta la cartella avvi il servizio ".\elasticsearch.bat"
es = Elasticsearch("http://localhost:9200")

# Nome dell'indice
index_name = "II_GoldStandard"

# Definizione dello schema (mappatura dei campi)
mapping = {
    "settings": {
        "analysis": {
            "analyzer": {
                "standard_analyzer": {
                    "type": "standard"
                }
            }
        }
    },
    "mappings": {
        "properties": {
            "title": {"type": "text", "analyzer": "standard"},  
            "year": {"type": "text"},
            "genre": {"type": "text"},  
            "country": {"type": "text"},
            "plot": {"type": "text", "analyzer": "standard"}
        }
    }
}

# Creazione dell'indice in Elasticsearch con la struttura assegnata ("mapping")
if not es.indices.exists(index=index_name):
    es.indices.create(index=index_name, body=mapping)

# carico il dataset
file = os.path.join("dataset-constr", "films.csv") 
df = pd.read_csv(file)


# Inserimento dati in Elasticsearch
for _, film in df.iterrows():
    doc = {
        "title": film["Title"],
        "year": str(film["Year"]),
        "genre": film["Genre"],
        "country": film["Country"],
        "plot": film["Plot"]
    }
    es.index(index=index_name, document=doc)

print("Indicizzazione II gold standard completata!")
